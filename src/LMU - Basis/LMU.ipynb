{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nengo\n",
    "import pandas as pd\n",
    "from nengo.ensemble import Ensemble\n",
    "from nengo.connection import Connection\n",
    "from nengo.node import Node\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'x_position', 'y_position', 'x_velocity', 'y_velocity', 'x_acceleration', 'y_acceleration', 'time_stamps', 'Neuron1', 'Neuron2', 'Neuron3', 'Neuron4', 'Neuron5', 'Neuron6', 'Neuron7', 'Neuron8', 'Neuron9', 'Neuron10', 'Neuron11', 'Neuron12', 'Neuron13', 'Neuron14', 'Neuron15', 'Neuron16', 'Neuron17', 'Neuron18', 'Neuron19', 'Neuron20', 'Neuron21', 'Neuron22', 'Neuron23', 'Neuron24', 'Neuron25', 'Neuron26', 'Neuron27', 'Neuron28', 'Neuron29', 'Neuron30', 'Neuron31', 'Neuron32', 'Neuron33', 'Neuron34', 'Neuron35', 'Neuron36', 'Neuron37', 'Neuron38', 'Neuron39', 'Neuron40', 'Neuron41', 'Neuron42', 'Neuron43', 'Neuron44', 'Neuron45', 'Neuron46', 'Neuron47', 'Neuron48', 'Neuron49', 'Neuron50', 'Neuron51', 'Neuron52', 'Neuron53', 'Neuron54', 'Neuron55', 'Neuron56', 'Neuron57', 'Neuron58', 'Neuron59', 'Neuron60', 'Neuron61', 'Neuron62', 'Neuron63', 'Neuron64', 'Neuron65', 'Neuron66', 'Neuron67', 'Neuron68', 'Neuron69', 'Neuron70', 'Neuron71', 'Neuron72', 'Neuron73', 'Neuron74', 'Neuron75', 'Neuron76', 'Neuron77', 'Neuron78', 'Neuron79', 'Neuron80', 'Neuron81', 'Neuron82', 'Neuron83', 'Neuron84', 'Neuron85', 'Neuron86', 'Neuron87', 'Neuron88', 'Neuron89', 'Neuron90', 'Neuron91', 'Neuron92', 'Neuron93', 'Neuron94']\n"
     ]
    }
   ],
   "source": [
    "# Change 'monkey' variable to the desired monkey dataset: MM_S1, MT_S1, MT_S2, MT_S3\n",
    "monkey = \"MM_S1\"\n",
    "\n",
    "# Datapath to get the raw data file (Stored in DataExtraction)\n",
    "datafile_path = f\"./../../Data Extraction/Extracted Data/{monkey}_raw.csv\"   \n",
    "\n",
    "df = pd.read_csv(datafile_path)\n",
    "\n",
    "headers = df.columns.tolist()\n",
    "n_neurons = sum(\"Neuron\" in string for string in headers)\n",
    "print(headers)\n",
    "\n",
    "# getting the activity matrix\n",
    "neuron_columns = [col for col in df.columns if col.startswith('Neuron')]\n",
    "activity_matrix = df[neuron_columns]\n",
    "\n",
    "# velocity data\n",
    "velocity_matrix = df[[\"x_velocity\", \"y_velocity\"]]\n",
    "# acceleration data\n",
    "acceleration_matrix = df[[\"x_acceleration\", \"y_acceleration\"]]\n",
    "\n",
    "# transpose the data\n",
    "activity_matrix_t = activity_matrix.transpose().to_numpy()\n",
    "velocity_matrix_t = velocity_matrix.transpose().to_numpy()\n",
    "acceleration_matrix_t = acceleration_matrix.transpose().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows 1066001\n",
      "The number of rows 94\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "num_rows= activity_matrix.shape[0]\n",
    "num_columns= activity_matrix.shape[1]\n",
    "print(\"The number of rows\" , num_rows)\n",
    "print(\"The number of rows\" , num_columns)\n",
    "\n",
    "num_neurons= num_columns\n",
    "print(num_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = activity_matrix_t \n",
    "scalar = np.max(acceleration_matrix_t)\n",
    "target_out = acceleration_matrix_t/scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "from utils.LMU_Stack import LMUStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "#synapses - act as filters or delays that are then applied to neural connections\n",
    "#purpose of this class --> any signal passing through this synapse will be delayed by 200 ms\n",
    "#ideal delay is a synapse that has been customed so that it delays the signal without filtering\n",
    "\n",
    "class IdealDelay(nengo.synapses.Synapse):\n",
    "    def __init__(self,delay):\n",
    "        super().__init__()\n",
    "        #stored delay value \n",
    "        self.delay= delay\n",
    "\n",
    "    #sets up the delayed processing of the input signals\n",
    "    def make_state(self,shape_in, shape_out, dt, dtype=None, y0=None):\n",
    "        return{}\n",
    "    \n",
    "    #function makes a delated output function that stores past inputs\n",
    "    def make_step(self, shape_in, shape_out, dt, rng, state):\n",
    "        #deque = double-ended queue that allows insertion and removal of elements from BOTH ends (front and back)\n",
    "        #delay buffer to store past inputs before they are output\n",
    "        buffer= deque([0]*int(self.delay/dt)) \n",
    "    \n",
    "        #processes the input x at time t \n",
    "        def delay_func(t,x):\n",
    "            #appends at the end (the right)\n",
    "            #stores newest input at the end of the queue\n",
    "\n",
    "            buffer.append(x.copy())\n",
    "\n",
    "            #appends at the front \n",
    "            #removes the oldest stored value from the front of the queue\n",
    "            #returns the oldest value from deque (the first value)\n",
    "            #FIFO (first in first out) - simulating delays\n",
    "            return buffer.popleft()\n",
    "        return delay_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "n_ensemble_neurons = 3000\n",
    "ensemble_radius = 1     # ? Represents the range of values for the neurons?\n",
    "ensemble_synapse = 0.025\n",
    "probe_synapse = 0.01\n",
    "running_time = 10\n",
    "training_time = 0.8*running_time # WHen does the model stop learning\n",
    "dt= 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = num_neurons\n",
    "out_dimension= 2\n",
    "num_degree= 2\n",
    "neurons= 100\n",
    "proj_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "[####################### Building... 73% ######                 ] ETA: 0:00:03"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with nengo.Network() as model:\n",
    "    input_node= nengo.Node(lambda t:spikes[int(t/dt)-1,:])\n",
    "    lmu_set= LMUStack(proj_dim, order= num_degree)\n",
    "    print(lmu_set.input.size_in)\n",
    "    print(lmu_set.output.size_out)\n",
    "\n",
    "    ##Where each of the channels from the input node (94 dims) are being mapped to individual neurons that contribute in varying amounts to each output dimension (10 dims in this case)\n",
    "    representation_ensemble= nengo.Ensemble(n_neurons=spikes.shape[1],dimensions=10 )\n",
    "\n",
    "    target_node= nengo.Node(lambda t: target_out[:,int(t/dt)-1])\n",
    "    inhib_node= nengo.Node(output=lambda t: t>=training_time)\n",
    "\n",
    "    intermediate_ens= nengo.Ensemble(dimensions*num_degree*neurons, proj_dim*num_degree) #\n",
    "    out_ens = nengo.Ensemble(n_ensemble_neurons, out_dimension, ensemble_radius)\n",
    "    err_ens = nengo.Ensemble(n_ensemble_neurons, out_dimension, ensemble_radius)\n",
    "\n",
    "    in_rep_ens_connection=  nengo.Connection(input_node, representation_ensemble.neurons, synapse=0.01)\n",
    "    rep_lmu_connection = nengo.Connection(representation_ensemble, lmu_set.input, transform=np.random.normal(0,1,(proj_dim, 10)))\n",
    "\n",
    "    lmu_intermediate_connection = nengo.Connection(lmu_set.output, intermediate_ens )\n",
    "    learning_connection= nengo.Connection(intermediate_ens, out_ens, function= lambda x:[0,0], learning_rule_type=nengo.PES(learning_rate= 2e-4))\n",
    "\n",
    "    nengo.Connection(out_ens, err_ens)\n",
    "\n",
    "    nengo.Connection(err_ens, learning_connection.learning_rule)\n",
    "    inhib_lrn_con = nengo.Connection(inhib_node, err_ens.neurons, transform=-20 * np.ones((err_ens.n_neurons, 1))) \n",
    "\n",
    "    p_out = nengo.Probe(out_ens, synapse=probe_synapse)\n",
    "    p_err = nengo.Probe(err_ens, synapse=probe_synapse)\n",
    "\n",
    "\n",
    "with nengo.Simulator(model, seed=0) as sim:\n",
    "    sim.run(2)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
